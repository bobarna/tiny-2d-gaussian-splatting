{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Gaussian Parameters in 2D for Synthetic Data and Image\n",
    "\n",
    "In this notebook, we'll be optimizing for 2D Gaussians to represent an image, while building up the intuition that generalizes to 3D Gaussian Splatting. \n",
    "\n",
    "In Part 1, we'll be targeting a \"synthetic\" image (originally reconstructed from Gaussians).\n",
    "In Part 2, we'll be optimizing for an actual target image.\n",
    "\n",
    "For inspiration, here are a couple of cool examples on shadertoy of what you could do with your 2D Gaussian parameters:\n",
    "- [https://www.shadertoy.com/view/tflXRB](https://www.shadertoy.com/view/tflXRB)\n",
    "- [https://www.shadertoy.com/view/dtSfDD](https://www.shadertoy.com/view/dtSfDD)\n",
    "- [https://www.shadertoy.com/view/MdfGDH](https://www.shadertoy.com/view/MdfGDH)\n",
    "- [https://www.shadertoy.com/view/4df3D8](https://www.shadertoy.com/view/4df3D8)\n",
    "- [https://www.shadertoy.com/view/4XXSDN](https://www.shadertoy.com/view/4XXSDN)\n",
    "\n",
    "For what it's worth, this notebook creates a cool video of the training process. \n",
    "\n",
    "*Note: I wrote a modified version of this notebook as part of the 3rd homework assignment for the Georgia Tech course CS8803/4803 CGA: Computer Graphics in the AI Era. You can find more information about the course here: [https://cgai-gatech.vercel.app/](https://cgai-gatech.vercel.app/). You can also find my corresponding guest lecture on 3D Gaussian Splatting on YouTube: [https://youtu.be/MBVmQSA24Yk](https://youtu.be/MBVmQSA24Yk)*    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "# Visu\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# file i/o\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# For assembling video\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Misc.\n",
    "from typing import Union\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm  # progress bar\n",
    "TIME_FORMAT = \"%Y-%m-%d %H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Choose between available PyTorch backends. Use GPU if available.\n",
    "DEVICE = torch.device('cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")  # Metal backend for Apple devices\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    \n",
    "print(f\"Using {DEVICE} backend (torch.device)\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Helper classes and functions\n",
    "\n",
    "You don't need to touch anything here. \n",
    "They are included here only to make the notebook self-contained, and include the following functionalities used in throughout the notebook:\n",
    "- Domain2D: handles the 2D domain and its discretization\n",
    "- Simplify handling input/output paths and filenames \n",
    "- Plotting helper functions\n",
    "- Very simple Timer class\n",
    "- Writing out parameters as JSON and assembling video\n",
    "\n",
    "If you're curious, feel free to dig in, though."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#@title Domain2D\n",
    "class Domain2D:\n",
    "    \"\"\"\n",
    "    Helper function for handling a 2D domain, discretized on a grid of given resolution.\n",
    "    \"\"\"\n",
    "    x_dim: tuple[float]\n",
    "    y_dim: tuple[float]\n",
    "    res_x: float\n",
    "    res_y: float\n",
    "    xx: torch.Tensor\n",
    "    yy: torch.Tensor\n",
    "\n",
    "    def __init__(self, x_dim, y_dim, res_x, res_y):\n",
    "        self.x_dim, self.y_dim = x_dim, y_dim\n",
    "        self.res_x, self.res_y = res_x, res_y\n",
    "\n",
    "        self.xx, self.yy = torch.meshgrid(\n",
    "            torch.linspace(self.x_dim[0], self.x_dim[1], self.res_x, device=DEVICE),\n",
    "            torch.linspace(self.y_dim[0], self.y_dim[1], self.res_y, device=DEVICE),\n",
    "            indexing='xy'\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        return (f\"Domain2D: {self.x_dim}x{self.y_dim} \"\n",
    "                f\"discretized on a {self.res_x}x{self.res_y} grid.\")\n",
    "    \n",
    "    def get_extent(self):\n",
    "        extent = (*self.x_dim, *self.y_dim)\n",
    "        return extent"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#@title Files and folders\n",
    "\n",
    "CURRENT_SCENE = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "DATA_FOLDER = pathlib.Path(\"data\")\n",
    "CURRENT_SCENE_FOLDER = DATA_FOLDER / pathlib.Path(CURRENT_SCENE)\n",
    "LAST_FILE_NAME = 0\n",
    "\n",
    "def save_fig_to_file(fig):\n",
    "    # Save plot to file as {curr_date}/{epoch}.jpg\n",
    "    global LAST_FILE_NAME\n",
    "    curr_image_file = CURRENT_SCENE_FOLDER / f\"{LAST_FILE_NAME}.jpg\"\n",
    "    fig.savefig(curr_image_file.absolute())\n",
    "    \n",
    "    LAST_FILE_NAME += 1\n",
    "    \n",
    "def initialize_file_names():\n",
    "    \"\"\"\n",
    "    Update current folder name and reset file names.\n",
    "    We might want to call this when a new optimization run starts.\n",
    "    \"\"\"\n",
    "    global LAST_FILE_NAME, CURRENT_SCENE, CURRENT_SCENE_FOLDER\n",
    "    \n",
    "    CURRENT_SCENE = datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    CURRENT_SCENE_FOLDER = DATA_FOLDER / pathlib.Path(CURRENT_SCENE)\n",
    "    \n",
    "    CURRENT_SCENE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "    LAST_FILE_NAME = 0\n",
    "    \n",
    "initialize_file_names()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#@title Plotting\n",
    "\n",
    "def plot_tensor_image(\n",
    "        image,\n",
    "        title: str = \"\",\n",
    "        _plt=plt,\n",
    "        extent=None,\n",
    "):\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.cpu().detach().numpy()\n",
    "\n",
    "    if image.shape[-1] == 3:\n",
    "        image = np.clip(image, 0, 1)\n",
    "        # plot (R,G,B) image\n",
    "        #  Clip image colors\n",
    "        \n",
    "    _plt.imshow(\n",
    "        image,\n",
    "        extent=extent,  # (left, right, bottom, top)\n",
    "        origin=\"lower\"\n",
    "    )\n",
    "\n",
    "    if _plt == plt:\n",
    "        _plt.title(title)\n",
    "    else:\n",
    "        _plt.title.set_text(title)\n",
    "\n",
    "\n",
    "def draw_outline(params, _plt=plt):\n",
    "    centers, sigmas, thetas = params[\"centers\"], params[\"sigmas\"], params[\"thetas\"]\n",
    "    # Convert to basic numpy array if necessary,\n",
    "    # bringing tensors to the cpu and detach from computing graph\n",
    "    if isinstance(centers, torch.Tensor):\n",
    "        centers = centers.cpu().detach().numpy()\n",
    "    if isinstance(sigmas, torch.Tensor):\n",
    "        sigmas = sigmas.cpu().detach().numpy()\n",
    "    if isinstance(thetas, torch.Tensor):\n",
    "        thetas = thetas.cpu().detach().numpy()\n",
    "\n",
    "    if not isinstance(_plt, plt.Axes):\n",
    "        _plt = _plt.gca()\n",
    "\n",
    "    # plot centers as red dots\n",
    "    _plt.scatter(x=centers[:, 0], y=centers[:, 1], c='r', s=1)\n",
    "\n",
    "    # draw ellipses\n",
    "    for i, c in enumerate(centers):\n",
    "        _plt.add_patch(\n",
    "            Ellipse(\n",
    "                (c[0], c[1]),\n",
    "                width=sigmas[i][0] * 3.5,\n",
    "                height=sigmas[i][1] * 3.5,\n",
    "                angle=thetas[i] * (180.0 / np.pi),\n",
    "                edgecolor='red',\n",
    "                facecolor='none',\n",
    "                linewidth=1,\n",
    "                alpha=1.0\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def assemble_plot_data(data, outline_params):\n",
    "    \"\"\"\n",
    "    Make the data ready for plotting with the `plot` function.\n",
    "    Calculates the number of rows and columns to be plotted based on the supplied data.\n",
    "\n",
    "    :param data: image data, or iterable of image data\n",
    "    :param outline_params: gaussian parameters used for plotting an overlay over the reconstructed image\n",
    "    :return: number of columns (int), rows (int), assembled data (np.ndarray) and outline parameters (list)\n",
    "    \"\"\"\n",
    "\n",
    "    def is_iterable(x):\n",
    "        return isinstance(x, list) or isinstance(x, tuple)\n",
    "\n",
    "    def is_2d_iterable(x):\n",
    "        return isinstance(x[0], list) or isinstance(x[0], tuple)\n",
    "\n",
    "    def get_numpy_data(d):\n",
    "        # Takes a single piece of plottable data, and makes it a numpy array\n",
    "        if isinstance(d, torch.Tensor):\n",
    "            d = d.cpu().detach().numpy()\n",
    "        d = np.array(d)\n",
    "        return d\n",
    "\n",
    "    # Create a 2D array of plottable data [[row_1_1, row_1_2 ...],[row_2_1, row_2_2, ...], ...]\n",
    "    # Each piece of data is uniformly converted to a numpy array\n",
    "    new_data = []\n",
    "    if is_iterable(data):\n",
    "        if is_2d_iterable(data):\n",
    "            for i in range(len(data)):\n",
    "                curr_row = []\n",
    "                for j in range(len(data[i])):\n",
    "                    curr_data = get_numpy_data(data[i][j])\n",
    "                    curr_row.append(curr_data)\n",
    "                new_data.append(curr_row)\n",
    "        else:\n",
    "            single_row = []\n",
    "            for i in range(len(data)):\n",
    "                curr_data = get_numpy_data(data[i])\n",
    "                single_row.append(curr_data)\n",
    "            new_data.append(single_row)\n",
    "    else:\n",
    "        # Single piece of data, but we still create a 2D array\n",
    "        new_data.append([get_numpy_data(data)])\n",
    "\n",
    "    data = new_data\n",
    "\n",
    "    # Calculate number of rows and columns in the plot\n",
    "    nrows = len(data)\n",
    "    ncols = len(data[0])\n",
    "\n",
    "    # Handle outline_params\n",
    "    if isinstance(outline_params, dict):\n",
    "        # If plotting only a single piece of data\n",
    "        assert ncols == nrows == 1, \"Non-list outline params is only allowed for plotting a single data.\"\n",
    "        outline_params = [[outline_params]]\n",
    "    if outline_params is not None:\n",
    "        if not all(p is None for p in outline_params):\n",
    "            if not isinstance(outline_params[0], list):\n",
    "                # If not already a 2D array, then\n",
    "                # wrap outline_params to be a 2D array for [row][col] indexing\n",
    "                outline_params = [outline_params]\n",
    "        else:\n",
    "            outline_params = None\n",
    "\n",
    "    # We could assert that outline_params should be None, or having the same shape as the data\n",
    "\n",
    "    return ncols, nrows, data, outline_params\n",
    "\n",
    "\n",
    "def assemble_titles(title, ncols, nrows):\n",
    "    \"\"\"\n",
    "    :param title: string or list of strings\n",
    "    :param ncols: number of columns in the plot\n",
    "    :param nrows: number of rows in the plot\n",
    "    :return: a 2D list of titles corresponding to a (ncols, nrows) plot.\n",
    "    \"\"\"\n",
    "    if isinstance(title, (tuple, list, dict)):\n",
    "        if isinstance(title[0], (tuple, list, dict)):\n",
    "            # Title is a 2D array of titles for each subplot, individually\n",
    "            assert len(title) == nrows and len(title[0]) == ncols\n",
    "        else:\n",
    "            # Wrap 1D list of titles to be a 2D array for a single row\n",
    "            title = [title]\n",
    "    else:\n",
    "        # Same title for each subplot\n",
    "        title = [[title] * ncols] * nrows\n",
    "\n",
    "    return title\n",
    "\n",
    "\n",
    "def plot(\n",
    "        data: Union[torch.Tensor, list, tuple, np.ndarray],\n",
    "        title: Union[str, list] = \"\",\n",
    "        figsize=(16, 6),\n",
    "        extent=None,\n",
    "        domain: Domain2D = None,  # if domain is not None, then it overwrite extent, xx and yy\n",
    "        outline_params=None,\n",
    "        show_plot=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main plotting function.\n",
    "    \"\"\"\n",
    "    ncols, nrows, data, outline_params = assemble_plot_data(data, outline_params)\n",
    "    titles = assemble_titles(title, ncols, nrows)\n",
    "\n",
    "    # Shape of axs, and existence of dimensions is dependent on number of rows and columns. If figure is (1,1)\n",
    "    # or either ncols or nrows is 1, then at least 1 of the dimensions will be missing from the axs list.\n",
    "    fig, axs = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "\n",
    "    # Make sure that axs is a 2D list of all subplot axes which can be indexed as `axs[row_i][col_j]`.\n",
    "    if nrows == ncols == 1:\n",
    "        axs = [[axs]]\n",
    "    elif nrows == 1:\n",
    "        axs = [axs]  # axs is a 1D list\n",
    "    elif ncols == 1:\n",
    "        axs = [[axs[i]] for i in range(len(axs))]  # axs is a 1D list, but we have to reshape it\n",
    "\n",
    "    # Set extent, xx and yy from domain if it was supplied\n",
    "    if domain is not None:\n",
    "        extent = domain.get_extent()\n",
    "\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            curr_data = data[i][j]\n",
    "            curr_ax = axs[i][j]\n",
    "            curr_title = titles[i][j]\n",
    "\n",
    "            if len(curr_data.shape) > 1:\n",
    "                # Plot scalar field or image data\n",
    "                plot_tensor_image(\n",
    "                    image=curr_data,\n",
    "                    title=curr_title,\n",
    "                    _plt=curr_ax,\n",
    "                    extent=extent,\n",
    "                )\n",
    "                if outline_params is not None and outline_params[i][j] is not None:\n",
    "                    draw_outline(params=outline_params[i][j], _plt=curr_ax)\n",
    "                curr_ax.set_aspect('equal')\n",
    "            elif len(curr_data.shape) == 1:\n",
    "                # Plot 1D data, e.g. loss curve\n",
    "                curr_ax.plot(curr_data)\n",
    "                curr_ax.set_xticks(range(0, len(curr_data), math.ceil(len(curr_data) / 8)))\n",
    "                curr_ax.set_title('Learning curve')\n",
    "                curr_ax.set_xlabel('Epoch')\n",
    "                curr_ax.set_ylabel('Loss')\n",
    "\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "    return fig"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#@title Timer\n",
    "class Timer:\n",
    "    \"\"\"\n",
    "    Super simple utility class for displaying elapsed time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.init_time = datetime.now()\n",
    "        # Step 1: Print the current time\n",
    "        print(\"Current time:\", self.init_time.strftime(TIME_FORMAT))\n",
    "\n",
    "    def print_time(self, reset_time = False):\n",
    "        # Print the time and the time elapsed since init_time\n",
    "        current_time = datetime.now()\n",
    "        elapsed_time = current_time - self.init_time\n",
    "\n",
    "        print(\"Current time:\", current_time.strftime(TIME_FORMAT))\n",
    "        print(\"Time elapsed:\", str(elapsed_time))\n",
    "\n",
    "        # Optionally overwrite initial time\n",
    "        if reset_time:\n",
    "            self.init_time = current_time\n",
    "\n",
    "    def get_elapsed_time(self) -> str:\n",
    "        delta_time = datetime.now() - self.init_time\n",
    "        return \"{:02}:{:02}:{:02}\".format(\n",
    "                delta_time.seconds // 3600,\n",
    "                (delta_time.seconds % 3600) // 60,\n",
    "                (delta_time.seconds % 60) // 1,\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#@title Misc.: json i/o and video\n",
    "\n",
    "def gaussians_from_json_file(filename):\n",
    "    filepath = pathlib.Path(filename)\n",
    "    filepath = CURRENT_SCENE_FOLDER / filepath\n",
    "\n",
    "    json_data = dict()\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        # TODO check for invalid input data here\n",
    "\n",
    "        json_data['gaussians'] = dict()\n",
    "        json_data['gaussians']['alphas']  = data['alphas']\n",
    "        json_data['gaussians']['centers'] = data['centers']\n",
    "        json_data['gaussians']['sigmas']  = data['sigmas']\n",
    "        json_data['gaussians']['thetas']  = data['thetas']\n",
    "\n",
    "        json_data['N']     = data['N']\n",
    "        json_data['dims']  = data['dims']\n",
    "        json_data['x_dim'] = data['x_dim']\n",
    "        json_data['y_dim'] = data['y_dim']\n",
    "        json_data['res_x'] = data['res_x']\n",
    "        json_data['res_y'] = data['res_y']\n",
    "\n",
    "    print(f\"Read gaussian scene from {filepath} with \"\n",
    "          f\"N={json_data['N']}, dims={json_data['dims']}, gaussians#={len(json_data['gaussians'])}\"\n",
    "          f\"#alphas={len(json_data['gaussians']['alphas'])}, \"\n",
    "          f\"#centers={len(json_data['gaussians']['centers'])}, \"\n",
    "          f\"#sigmas={len(json_data['gaussians']['sigmas'])}, \"\n",
    "          f\"#thetas={len(json_data['gaussians']['thetas'])}\")\n",
    "\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def gaussians_to_json_file(filename, params, domain):\n",
    "    \"\"\"\n",
    "    filename: relative to the current scene\n",
    "    \"\"\"\n",
    "    filepath = CURRENT_SCENE_FOLDER / filename\n",
    "\n",
    "    # Convert PyTorch tensors to Python floats (and lists of them)\n",
    "    alphas_item = [[x.item() for x in a] for a in params['alphas']]\n",
    "    centers_item = [[x.item() for x in c] for c in params['centers']]\n",
    "    sigmas_item = [[x.item() for x in s] for s in params['sigmas']]\n",
    "    # Can't array comprehend over 0D tensor\n",
    "    thetas_item = [t.item() for t in params['thetas']]\n",
    "\n",
    "    scene_data = {\n",
    "        \"x_dim\": domain.x_dim,\n",
    "        \"y_dim\": domain.y_dim,\n",
    "        \"res_x\": domain.res_x,\n",
    "        \"res_y\": domain.res_y,\n",
    "        \"N\": params['alphas'].shape[0],\n",
    "        \"dims\": params['alphas'].shape[-1],\n",
    "        \"alphas\": alphas_item,\n",
    "        \"centers\": centers_item,\n",
    "        \"sigmas\": sigmas_item,\n",
    "        \"thetas\": thetas_item\n",
    "    }\n",
    "\n",
    "    with open(filepath, 'w') as file:\n",
    "        json.dump(scene_data, file, indent=2)\n",
    "\n",
    "    print(f\"2D Gaussian Scene written to {filepath}.\")\n",
    "    \n",
    "    \n",
    "def assemble_video(image_folder: str, output_file: str=\"video.mp4\", fps=10):\n",
    "    \"\"\"\n",
    "    image_folder: absolute path\n",
    "    output_file: name of output file\n",
    "    \"\"\"\n",
    "    image_files = sorted(glob.glob(f\"{image_folder}/*.jpg\"), key=lambda x: int(Path(x).stem))\n",
    "    if not image_files:\n",
    "        raise ValueError(\"No .jpg files found in the specified directory.\")\n",
    "\n",
    "    # Read the first image to get the dimensions\n",
    "    image_0 = cv2.imread(image_files[0])\n",
    "    height, width, layers = image_0.shape\n",
    "\n",
    "    # Adjust FPS based on the number of images\n",
    "    if len(image_files) > 200:\n",
    "        fps = 30\n",
    "    elif len(image_files) > 100:\n",
    "        fps = 20\n",
    "\n",
    "    # Create Video Writer with proper codec\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'X264')  # Using H.264 codec\n",
    "    video = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "\n",
    "    # Write frames to video\n",
    "    for image_file in image_files:\n",
    "        video.write(cv2.imread(image_file))\n",
    "\n",
    "    video.release()\n",
    "    print(f\"Video saved as {output_file}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2D Gaussian Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A 2D Gaussian is parameterized by:\n",
    "- centers $c = [c_x, c_y]^T$\n",
    "- scales $\\sigma = [\\sigma_x, \\sigma_y]^T$\n",
    "- scalar rotation $\\theta$ (Note: we could also use a unit-length complex number in the spirit of using quaternions in 3D, but a scalar rotation is perfectly fine.) \n",
    "\n",
    "Its value at point $\\bf{p}$ is given by\n",
    "$$\n",
    "f(p) = \\text{exp}\\left(\n",
    "  -\\frac{1}{2} \n",
    "  (p - c)^T \n",
    "  \\Sigma^{-1}\n",
    "  (p - c)\n",
    "\\right),\n",
    "$$\n",
    "\n",
    "where the covariance matrix $\\Sigma$ describes the shape of the Gaussian, and we build it as\n",
    "\n",
    "$$\n",
    "\\Sigma = \n",
    "      RSS^TR^T,\n",
    "$$\n",
    "\n",
    "making use of (1) $(AB)^{-1} = B^{-1} A^{-1}$, and (2) $R^{-1} = R^T$ for rotational matrices, we have\n",
    "$$\n",
    "\\Sigma^{-1} = R(SS^{T})^{-1}R^T.\n",
    "$$\n",
    "\n",
    "If we want to write out our 2D Gaussian function explicitly, we have:\n",
    "\n",
    "$$\n",
    "f\\left(\\begin{bmatrix}\n",
    "    p_x\\\\\n",
    "    p_y\n",
    "\\end{bmatrix}\\right) \n",
    "= \\text{exp}\\left(\n",
    "    -\\frac{1}{2} \n",
    "    \\begin{bmatrix}\n",
    "        p_x - c_x &\n",
    "        p_y - c_y\n",
    "    \\end{bmatrix}\n",
    "    \\Sigma^{-1}\n",
    "    \\begin{bmatrix}\n",
    "        p_x - c_x\\\\\n",
    "        p_y - c_y\n",
    "    \\end{bmatrix}\n",
    "\\right),\n",
    "$$ \n",
    "\n",
    "where\n",
    "$$\n",
    "    \\Sigma^{-1} = \n",
    "      \\begin{bmatrix}\n",
    "        \\cos \\theta & -\\sin\\theta\\\\\n",
    "        \\sin \\theta & \\cos \\theta\n",
    "      \\end{bmatrix}\n",
    "      \\begin{bmatrix}\n",
    "        \\frac{1}{\\sigma_x^2} & 0 \\\\\n",
    "        0 & \\frac{1}{\\sigma_y^2}\n",
    "      \\end{bmatrix}\n",
    "      \\begin{bmatrix}\n",
    "        \\cos \\theta & \\sin\\theta\\\\\n",
    "        -\\sin \\theta & \\cos \\theta\n",
    "      \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "To reconstruct a 2D image, we add together function of this form, but also multiply them by an \"alpha\" channel. In the original 3DGS implementation, they use a Gaussian-wise $\\alpha \\in \\mathbb{R}$ and RGB color $[c_r, c_g, c_b] \\in \\mathbb{R}^3$ (converted from spherical harmonics in 3D, given our current view direction).\n",
    "\n",
    "To simplify things here, we multiply these together, and store $\\boldsymbol{\\alpha} = \\alpha \\cdot [ c_r, c_g, c_b ]$ for each Gaussian.\n",
    "\n",
    "Thus, we reconstruct each pixel $\\textbf{p}$ of our 2D image $\\textbf{I}$ by summing together to contribution from N Gaussians as \n",
    "\n",
    "$$\n",
    "I(p) = \\sum_{i=1}^{N} \\boldsymbol{\\alpha}_i f_i(p).\n",
    "$$\n",
    "\n",
    "This is implemented in `reconstruct_gaussian_2d`, with the two helper functions `build_sigma_invs` and `build_position_tensor`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def build_sigma_invs(thetas: torch.Tensor, sigmas: torch.Tensor):\n",
    "    # Construct batch of rotation matrices R\n",
    "    cos_thetas = torch.cos(thetas)\n",
    "    sin_thetas = torch.sin(thetas)\n",
    "    R = torch.stack([\n",
    "        torch.stack((cos_thetas, -sin_thetas), dim=-1),\n",
    "        torch.stack((sin_thetas, cos_thetas), dim=-1)\n",
    "    ], dim=-2)\n",
    "\n",
    "    #  Construct inverse scaling matrix squared (inverse covariance matrix)\n",
    "    #  N diagonal (scaling) matrices represented only by their diagonal part\n",
    "    diag_inv_squared_sigmas = torch.diag_embed((1.0 / (sigmas ** 2)))\n",
    "\n",
    "    #  R @ scaling_matrix @ R.T along all gaussians\n",
    "    #  note: the transpose part could be incorporated into the einsum as ('bik,bkl,bkj->bij', R, S, R),\n",
    "    #    but this feels more descriptive.\n",
    "    sigma_invs = torch.einsum(\"bik,bkl,blj->bij\", R, diag_inv_squared_sigmas, R.transpose(1, 2))\n",
    "\n",
    "    return sigma_invs\n",
    "\n",
    "\n",
    "def build_position_tensor(xx, yy, centers: torch.Tensor):\n",
    "    # Match center and grid tensor dimensions for translation\n",
    "    # Reshape centers: [N, 2] -> [N, 1, 1, 2]\n",
    "    expanded_centers = centers.view(-1, 1, 1, 2)\n",
    "    # Expand to match the grid shape [N, res_y, res_x, 2]\n",
    "    expanded_centers = expanded_centers.expand(-1, *xx.shape, 2)\n",
    "\n",
    "    # Create a combined grid of x and y coordinates\n",
    "    # [res_x, res_y, 2] ('xy' indexing)\n",
    "    xy_grid = torch.stack([xx, yy], dim=-1)\n",
    "    # [1, res_y, res_x, 2]\n",
    "    expanded_xy_grid = xy_grid.unsqueeze(0)\n",
    "    # ([x,y]-[c_ix, c_iy]) for calculating the function values at the given x positions\n",
    "    pos = expanded_xy_grid - expanded_centers\n",
    "    \n",
    "    return pos\n",
    "\n",
    "\n",
    "def reconstruct_gaussian_2d(params: dict, domain: Domain2D):\n",
    "    \"\"\"\n",
    "    Sample Gaussian functions on a 2D domain, parametrized by their colors (alphas),\n",
    "    positions (centers), local scales (sigmas) and rotations (thetas). \n",
    "    \"\"\"\n",
    "    # We expect that these exist in the params dict, and that they are torch.Tensors\n",
    "    alphas = params['alphas']\n",
    "    centers = params['centers']\n",
    "    sigmas = params['sigmas']\n",
    "    thetas = params['thetas']\n",
    "    \n",
    "    sigma_invs = build_sigma_invs(thetas, sigmas)\n",
    "    pos = build_position_tensor(domain.xx, domain.yy, centers)\n",
    "    # (pos-c_i)^T @ sigma^{-1} @ (pos-c_i) for all coords and all gaussians\n",
    "    exponent = torch.einsum('nxyj,nij,nxyi->nxy', pos, sigma_invs, pos)\n",
    "\n",
    "    # Calculate the scalar Gaussian function f(x) for each Gaussian\n",
    "    # [N, res_x, res_y]\n",
    "    f_x = torch.exp(-0.5 * exponent)\n",
    "    # Calculate linear combination with the alpha coefficients\n",
    "    # return a value for each pixel (self.x, self.y) as a matrix of values.\n",
    "    alpha_f_x = torch.einsum(\"na,nxy->xya\", alphas, f_x)\n",
    "\n",
    "    return alpha_f_x"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "*A note on batching: after implementing the batched version below, I tried out a simple Python for-loop, which seems to run comparably to the batched version on the GPUs I tested it on. And in some cases, the Python-based for loop ran faster than my batched version. This might have to do something with creating `N` copies of the full grid for each Gaussian, which is slightly wasteful.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1: Optimize for Synthetic Ground Truth\n",
    "## 1.1. Generate Synthetic Ground Truth\n",
    "\n",
    "Let's test out the above functionalities by reconstructing a 2D Image from our Gaussians."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DOMAIN = Domain2D(\n",
    "    x_dim=[-5.0, 5.0],  # virtual dimensions\n",
    "    y_dim=[-5.0, 5.0],\n",
    "    res_x=100,  # resolution\n",
    "    res_y=100\n",
    ")\n",
    "\n",
    "# Define the parameters in a dictionary.\n",
    "# Create torch tensors on the selected computing device (cpu/metal/cuda).\n",
    "target_params = {\n",
    "    # RGB colors\n",
    "    'alphas': torch.tensor([\n",
    "        [0.7, 0.1, 0.2], \n",
    "        [0.3, 0.8, 0.1]\n",
    "    ], device=DEVICE),\n",
    "    # X,Y coordinates\n",
    "    'centers': torch.tensor([\n",
    "        [-3.0, 1.5], \n",
    "        [1.5, 2.5]\n",
    "    ], device=DEVICE),\n",
    "    # Scales along local (X, Y)\n",
    "    'sigmas': torch.tensor([\n",
    "        [2.0, 1.5], \n",
    "        [1.5, 0.5]\n",
    "    ], device=DEVICE),\n",
    "    # Rotations\n",
    "    'thetas': torch.tensor([\n",
    "        0.2, 0.8\n",
    "    ], device=DEVICE)\n",
    "}\n",
    "\n",
    "# Reconstruct the 2D Gaussians on a 2D grid.\n",
    "# Note: the detach() function is needed, because we just want to generate some static \n",
    "#   synthetic target image data. If we didn't detach, then the computation that produced \n",
    "#   it would become part of PyTorch's computation graph when we calculate the loss later on. \n",
    "#   Or put simply: we just want a plain array of numbers.\n",
    "target_image_synthetic = reconstruct_gaussian_2d(target_params, domain=DOMAIN).detach()\n",
    "\n",
    "# Plot the target scene using the helper plotting function\n",
    "plot(data=target_image_synthetic, title=\"Synthetic test image\", domain=DOMAIN, figsize=(3,3));"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Initial random Gaussian parameters for the optimization\n",
    "\n",
    "Now we run a simple experiment: let's forget that the above \"ground truth image\" came from our predefined Gaussians. Can we find a set of Gaussian parameters that describe the same image?\n",
    "\n",
    "Let's generate a random set of Gaussian parameters, and look at what that gives us."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "N = 20  # Number of Gaussians\n",
    "\n",
    "# Collect the parameters we want to optimize in a dictionary.\n",
    "# Feel free to play around with the random initialization!\n",
    "params_opt_synthetic = {\n",
    "    # get random RGB color for N gaussian\n",
    "    'alphas': nn.Parameter(torch.tensor(\n",
    "        [[random.random() for _ in range(3)] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # positions: scatter N random gaussians in our domain\n",
    "    'centers': nn.Parameter(torch.tensor(\n",
    "        [[random.uniform(*DOMAIN.x_dim), random.uniform(*DOMAIN.y_dim)] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # Scales along local (X, Y). Start out with isotropic gaussian\n",
    "    'sigmas': nn.Parameter(torch.tensor(\n",
    "        [[1.5, 1.5] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # Rotations\n",
    "    'thetas': nn.Parameter(torch.tensor(\n",
    "        [0.0]*N, # or for random rotation: np.random.rand() * 2 * np.pi\n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting initial gaussians\n",
    "initial_image = reconstruct_gaussian_2d(\n",
    "    params_opt_synthetic, \n",
    "    domain=DOMAIN\n",
    ")\n",
    "\n",
    "plot(\n",
    "    data=[target_image_synthetic, initial_image, initial_image],\n",
    "    title=[\"Target Image\", \"Initial Gaussians\", \"\"],\n",
    "    outline_params=[None, None, params_opt_synthetic],\n",
    "    extent=DOMAIN.get_extent(),\n",
    "    figsize=(7,10)\n",
    ");"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3. Optimization\n",
    "### 1.3.1 Initialize the optimizer\n",
    "\n",
    "Now let's tweak our initial Gaussians. We would like the image reconstructed from them to be the same as our ground truth image $\\textbf{I}$. Calling our set of Gaussian parameters $\\xi$ (containing alphas, centers, sigmas, and thetas), we can quantify this in a scalar-valued loss function:\n",
    " \n",
    "$$\n",
    "    \\mathcal{L}(\\textbf{I}, \\xi) = \n",
    "    \\sum_{\\text{pixels \\textbf{p}} \\in \\text{\\textbf{I}}} \n",
    "        ||\n",
    "            \\boldsymbol{I}(\\boldsymbol{p}) - \\sum_{i}^N \\boldsymbol{\\alpha}_i f_i(\\boldsymbol{p}; \\xi_i)\n",
    "        ||,\n",
    "$$\n",
    "\n",
    "where $f_i(\\cdot;\\xi_i)$ simply denotes that we are using the $i$th Gaussian parameters.\n",
    "\n",
    "For this notebook, both $L_1$ and $L_2$ losses work fine. In the original 3DGS paper, they add together a D-SSIM loss with a weight of $0.2$ and an $L_1$ loss with a weight of $0.8$ to get their scalar loss.\n",
    "\n",
    "To find Gaussian parameters $\\xi$ that minimize this loss function, we use an Adam optimizer that iteratively steps towards the gradient of the loss w.r.t. the parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "params_keys = ['alphas', 'centers', 'sigmas', 'thetas']  # Note: params_opt.keys() is unordered.\n",
    "params_dict_for_optimizer = [{'params': params_opt_synthetic[p], 'name': p} for p in params_keys]\n",
    "# Note: this is the same as:\n",
    "# params_dict_for_optimizer = [\n",
    "#     {'params': params_opt_synthetic['alphas'], 'name': 'alphas'},\n",
    "#     {'params': params_opt_synthetic['centers'], 'name': 'centers'},\n",
    "#     {'params': params_opt_synthetic['sigmas'], 'name': 'sigmas'},\n",
    "#     {'params': params_opt_synthetic['thetas'], 'name': 'thetas'}\n",
    "# ]\n",
    "\n",
    "# We can also set per-parameter-group learning rates beyond the default learning rate below. \n",
    "# We can use this for freezing a given parameter group (e.g. leave particles in the same position).\n",
    "# For more details on setting up and using the optimizer: https://pytorch.org/docs/stable/optim.html\n",
    "# lr_dict = {'alphas': 0.01, 'centers': 0.2, 'sigmas': 0.0, 'thetas': 0.0}\n",
    "# for i, param_key in enumerate(params_keys):\n",
    "#     if param_key in lr_dict:\n",
    "#         params_dict_for_optimizer[i]['lr'] = lr_dict[param_key]\n",
    "\n",
    "\n",
    "# Initial learning rate\n",
    "lr = 0.1\n",
    "\n",
    "# Initialize an Adam optimizer\n",
    "optimizer = torch.optim.Adam(params_dict_for_optimizer, lr=lr)\n",
    "\n",
    "# Define the loss function we want to use in the optimziation loop below\n",
    "def loss_function(prediction, target):\n",
    "    # Note: we could add SSIM loss here. For demo purposes, both L1 and L2 seems to be good enough.\n",
    "    # See e.g.: https://github.com/VainF/pytorch-msssim\n",
    "    loss = torch.nn.L1Loss()  # L1\n",
    "    # loss = torch.nn.MSELoss()  # L2\n",
    "    return loss(prediction, target)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.2 Optimization loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_save_interval = 1  # Whether to same image\n",
    "num_epochs = 200\n",
    "display_plots = False  # Whether to plot in the notebook. Useful for not cluttering the notebook.\n",
    "save_plots = True  # Whether to write out images into a folder.\n",
    "\n",
    "if save_plots:\n",
    "    # Set the output folder to be the current time, and restart naming of the file names\n",
    "    initialize_file_names()\n",
    "    print(f\"Starting optimization. Outputting results into folder `{CURRENT_SCENE_FOLDER}`.\")\n",
    "else:\n",
    "    print(f\"Starting optimization without saving the results into file.\")\n",
    "    \n",
    "timer = Timer()\n",
    "\n",
    "# Keep track of lost history\n",
    "loss_trajectory = []\n",
    "\n",
    "epoch_progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in epoch_progress_bar:\n",
    "    # Forward pass, i.e. combining Gaussians into an image\n",
    "    curr_image = reconstruct_gaussian_2d(params_opt_synthetic, domain=DOMAIN)\n",
    "\n",
    "    # Calculate and save current loss between output and target\n",
    "    curr_loss = loss_function(curr_image, target_image_synthetic)\n",
    "    loss_trajectory.append(curr_loss.detach().cpu().numpy())\n",
    "\n",
    "    # Zero out gradients before running backward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute gradient of the loss (w.r.t. gaussian parameters)\n",
    "    curr_loss.backward()\n",
    "\n",
    "    # Perform an optimization epoch (i.e. update gaussian parameters)\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Note: Densification and Pruning could be done here by removing Gaussians\n",
    "        #       that are too small/stretched/out of bounds/etc,\n",
    "        #       and duplicating Gaussians based on their positional gradient.\n",
    "\n",
    "        # Optionally display/save image\n",
    "        if display_plots or save_plots:\n",
    "            if epoch % image_save_interval == 0:\n",
    "                fig = plot(\n",
    "                    data=[curr_image, curr_image, target_image_synthetic, loss_trajectory],\n",
    "                    outline_params=[None, params_opt_synthetic, None, None],\n",
    "                    title=[\n",
    "                        f\"Optim at epoch {epoch}\",\n",
    "                        f\"Gaussians (N={N})\",\n",
    "                        f\"Target image\",\n",
    "                        f\"Loss history\"\n",
    "                    ],\n",
    "                    domain=DOMAIN,\n",
    "                    show_plot=display_plots  # Optionally, don't clutter the notebook with showing the plot here.\n",
    "                )\n",
    "            if save_plots:\n",
    "                # Save plot to file as {curr_date}/{epoch}.jpg\n",
    "                save_fig_to_file(fig)\n",
    "            plt.close(fig)  # close the current figure\n",
    "\n",
    "        # Print out optimization details\n",
    "        progress_text = (\n",
    "            f\"Step {epoch}, \"\n",
    "            f\"Loss: {curr_loss.item()}, \"\n",
    "            f\"{timer.get_elapsed_time()}, \"\n",
    "            f\"N = {N}\"\n",
    "        )\n",
    "        \n",
    "        epoch_progress_bar.set_description(progress_text)\n",
    "\n",
    "        # You can try experimenting with a learning rate scheduler.\n",
    "        # In the simplest case, you can decrease the learning rate\n",
    "        # at some predefined intervals.\n",
    "        # if epoch % 800 == 0 and epoch > 0:\n",
    "        #     for param_group in self.optimizer.param_groups:\n",
    "        #         param_group['lr'] *= 0.5\n",
    "        #         print(f\"lr: {param_group['lr']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.3 Plotting final result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "curr_image = reconstruct_gaussian_2d(params_opt_synthetic, domain=DOMAIN)\n",
    "\n",
    "# Plotting final result\n",
    "plot(\n",
    "    data=[curr_image, curr_image, target_image_synthetic],\n",
    "    outline_params=[None, params_opt_synthetic, None],\n",
    "    title=[\n",
    "        f\"Result of optimization\",\n",
    "        f\"Gaussians (N={N})\",\n",
    "        f\"Target image\"\n",
    "    ],\n",
    "    domain=DOMAIN,\n",
    "    figsize=(10,6)\n",
    ")\n",
    "\n",
    "print(f\"Final params: {params_opt_synthetic}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Write out the final params into a json data file:\n",
    "gaussians_to_json_file(\"optimized-params-synthetic.json\", params=params_opt_synthetic, domain=DOMAIN)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Note: you can ignore the \"Corrupt JPEG data\" warnings if you see any. The video should still render properly.\n",
    "assemble_video(CURRENT_SCENE_FOLDER, str(\"anim-synthetic.mp4\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2: Optimize for Target Image\n",
    "\n",
    "In the second part of this notebook, we want to find Gaussian parameters that match an actual image. The process will be essentially the same as in Part 1, but you might need to tune some hyperparameters for the best result, such as the number of iterations, learning rate, number of Gaussians, etc. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load target image  "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_input_image_as_torch_tensor(filename: str):\n",
    "    full_filename = DATA_FOLDER / filename\n",
    "    # Erase alpha channel ([:,:,0:3])\n",
    "    image_np = np.array(plt.imread(full_filename)[:, :, 0:3])\n",
    "\n",
    "    # transpose, and upside-down image to match 'xy' indexing of our meshgrid\n",
    "    # image_np = np.transpose(image_np, (1, 0, 2))  # Swapping height and width\n",
    "    image_np = np.flipud(image_np)  # Flipping upside down\n",
    "\n",
    "    image_torch = torch.tensor(image_np.copy(), requires_grad=False, device=DEVICE)\n",
    "\n",
    "    return image_torch"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target input image as a torch tensor (requires_grad = False)\n",
    "# Expected in the `data` folder.\n",
    "file_name = \"mona-lisa.png\"\n",
    "target_image: torch.Tensor = get_input_image_as_torch_tensor(file_name)\n",
    "\n",
    "# Plot\n",
    "plot(target_image, \"Target Image\", (4, 3))\n",
    "\n",
    "# Same as target image pixel dimensions\n",
    "RES_X = target_image.shape[1]\n",
    "RES_Y = target_image.shape[0]\n",
    "x_to_y_ratio = float(RES_X) / float(RES_Y)\n",
    "\n",
    "X_DIM = (-5.0, 5.0)\n",
    "Y_DIM = (X_DIM[0]/x_to_y_ratio, X_DIM[1]/x_to_y_ratio)\n",
    "\n",
    "DOMAIN = Domain2D(x_dim=X_DIM, y_dim=Y_DIM, res_x=RES_X, res_y=RES_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2. Initial random Gaussian parameters for the optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "N = 100  # Number of Gaussians\n",
    "\n",
    "# Collect the parameters we want to optimize in a dictionary\n",
    "params_opt_image = {\n",
    "    # get random RGB color for N gaussian\n",
    "    'alphas': nn.Parameter(torch.tensor(\n",
    "        [[random.random() for _ in range(3)] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # positions: scatter N random gaussians in our domain\n",
    "    'centers': nn.Parameter(torch.tensor(\n",
    "        [[random.uniform(*DOMAIN.x_dim), random.uniform(*DOMAIN.y_dim)] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # Scales along local (X, Y). Start out with isotropic gaussian\n",
    "    'sigmas': nn.Parameter(torch.tensor(\n",
    "        [[0.3, 0.3] for _ in range(N)], \n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "    # Rotations\n",
    "    'thetas': nn.Parameter(torch.tensor(\n",
    "        [0.0]*N, # or for random rotation: np.random.rand() * 2 * np.pi\n",
    "        requires_grad=True, device=DEVICE\n",
    "    )),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting initial gaussians\n",
    "initial_image = reconstruct_gaussian_2d(\n",
    "    params_opt_image, \n",
    "    domain=DOMAIN\n",
    ")\n",
    "\n",
    "plot(\n",
    "    data=[target_image, initial_image, initial_image],\n",
    "    title=[\"Target Image\", \"Initial Gaussians\", \"\"],\n",
    "    outline_params=[None, None, params_opt_image],\n",
    "    extent=DOMAIN.get_extent(),\n",
    "    figsize=(7,10)\n",
    ");"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3. Optimization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.1 Initialize the optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "params_keys = ['alphas', 'centers', 'sigmas', 'thetas']  # Note: params_opt.keys() is unordered.\n",
    "params_dict_for_optimizer = [{'params': params_opt_image[p], 'name': p} for p in params_keys]\n",
    "# Note: this is the same as:\n",
    "# params_dict_for_optimizer = [\n",
    "#     {'params': params_opt_image['alphas'], 'name': 'alphas'},\n",
    "#     {'params': params_opt_image['centers'], 'name': 'centers'},\n",
    "#     {'params': params_opt_image['sigmas'], 'name': 'sigmas'},\n",
    "#     {'params': params_opt_image['thetas'], 'name': 'thetas'}\n",
    "# ]\n",
    "\n",
    "# We can also set per-parameter-group learning rates beyond the default learning rate below. \n",
    "# We can use this for freezing a given parameter group (e.g. leave particles in the same position).\n",
    "# For more details on setting up and using the optimizer: https://pytorch.org/docs/stable/optim.html\n",
    "# lr_dict = {'alphas': 0.01, 'centers': 0.2, 'sigmas': 0.0, 'thetas': 0.0}\n",
    "# for i, param_key in enumerate(params_keys):\n",
    "#     if param_key in lr_dict:\n",
    "#         params_dict_for_optimizer[i]['lr'] = lr_dict[param_key]\n",
    "\n",
    "\n",
    "# Initial learning rate (default for all parameters unless a per-parameter lr is defined -- see above)\n",
    "lr = 0.1\n",
    "\n",
    "# Initialize an Adam optimizer\n",
    "optimizer = torch.optim.Adam(params_dict_for_optimizer, lr=lr)\n",
    "\n",
    "def loss_function(prediction, target):\n",
    "    # Note: we could add SSIM loss here. For demo purposes, both L1 and L2 seems to be good enough.\n",
    "    # See e.g.: https://github.com/VainF/pytorch-msssim\n",
    "    loss = torch.nn.L1Loss()  # L1\n",
    "    # loss = torch.nn.MSELoss()  # L2\n",
    "    return loss(prediction, target)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.2. Optimization loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Intervals during optimization\n",
    "image_save_interval = 1\n",
    "num_epochs = 50  # number of epochs to optimize for\n",
    "display_plots = False  # For not cluttering the notebook\n",
    "save_plots = True  # Writing out images into a folder\n",
    "\n",
    "if save_plots:\n",
    "    # Set the output folder to be the current time, and restart naming of the file names\n",
    "    initialize_file_names()\n",
    "    print(f\"Starting optimization. Outputting results into folder `{CURRENT_SCENE_FOLDER}`.\")\n",
    "else:\n",
    "    print(f\"Starting optimization without saving the results into file.\")\n",
    "    \n",
    "timer = Timer()\n",
    "\n",
    "# Keep track of lost history\n",
    "loss_trajectory = []\n",
    "\n",
    "epoch_progress_bar = tqdm(range(num_epochs))\n",
    "for epoch in epoch_progress_bar:\n",
    "    # Forward pass, i.e. combining Gaussians into an image\n",
    "    curr_image = reconstruct_gaussian_2d(params_opt_image, domain=DOMAIN)\n",
    "\n",
    "    # Calculate and save current loss between output and target\n",
    "    curr_loss = loss_function(curr_image, target_image)\n",
    "    loss_trajectory.append(curr_loss.detach().cpu().numpy())\n",
    "\n",
    "    # Zero out gradients before running backward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute gradient of the loss (w.r.t. gaussian parameters)\n",
    "    curr_loss.backward()\n",
    "\n",
    "    # Perform an optimization epoch (i.e. update gaussian parameters)\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Optionally display/save image\n",
    "        if display_plots or save_plots:\n",
    "            if epoch % image_save_interval == 0:\n",
    "                fig = plot(\n",
    "                    data=[curr_image, curr_image, target_image, loss_trajectory],\n",
    "                    outline_params=[None, params_opt_image, None, None],\n",
    "                    title=[\n",
    "                        f\"Optim at epoch {epoch}\",\n",
    "                        f\"Gaussians (N={N})\",\n",
    "                        f\"Target image\",\n",
    "                        f\"Loss history\"\n",
    "                    ],\n",
    "                    domain=DOMAIN,\n",
    "                    show_plot=display_plots  # Optionally, don't clutter the notebook with showing the plot here.\n",
    "                )\n",
    "            if save_plots:\n",
    "                # Save plot to file as {curr_date}/{epoch}.jpg\n",
    "                save_fig_to_file(fig)\n",
    "            plt.close(fig)  # close the current figure\n",
    "\n",
    "        # Print out optimization details\n",
    "        progress_text = (\n",
    "            f\"Step {epoch}, \"\n",
    "            f\"Loss: {curr_loss.item()}, \"\n",
    "            f\"{timer.get_elapsed_time()}, \"\n",
    "            f\"N = {N}\"\n",
    "        )\n",
    "        \n",
    "        epoch_progress_bar.set_description(progress_text)\n",
    "\n",
    "        # You can experiment with changing the learning rate here\n",
    "        # if epoch % 800 == 0 and epoch > 0:\n",
    "        #     for param_group in self.optimizer.param_groups:\n",
    "        #         param_group['lr'] *= 0.5\n",
    "        #         print(f\"lr: {param_group['lr']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.3. Plotting final result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "curr_image = reconstruct_gaussian_2d(params_opt_image, domain=DOMAIN)\n",
    "\n",
    "# Plotting final result\n",
    "plot(\n",
    "    data=[curr_image, curr_image, target_image],\n",
    "    outline_params=[None, params_opt_image, None],\n",
    "    title=[\n",
    "        f\"Result of optimization\",\n",
    "        f\"Gaussians (N={N})\",\n",
    "        f\"Target image\"\n",
    "    ],\n",
    "    domain=DOMAIN,\n",
    "    figsize=(10,6)\n",
    ")\n",
    "\n",
    "print(f\"Final params: {params_opt_image}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Write out the final params into a json data file:\n",
    "gaussians_to_json_file(\"optimized-params-image.json\", params=params_opt_image, domain=DOMAIN)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assemble_video(CURRENT_SCENE_FOLDER, str(\"anim-image.mp4\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
